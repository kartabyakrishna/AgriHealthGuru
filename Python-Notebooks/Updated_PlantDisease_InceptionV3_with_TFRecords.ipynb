{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "6de63626",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import os\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import random as rn\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "from keras.layers import Conv2D, MaxPooling2D, GlobalAvgPool2D\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, Flatten, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0f7d1018",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Kartabya Krishna\\AppData\\Local\\Temp\\ipykernel_28968\\3039545816.py:19: DeprecationWarning: tostring() is deprecated. Use tobytes() instead.\n",
      "  img_bytes = cv2.imencode('.jpg', image_resized)[1].tostring()\n"
     ]
    }
   ],
   "source": [
    "\n",
    "def _bytes_feature(value):\n",
    "    \"\"\"Returns a bytes_list from a string / byte.\"\"\"\n",
    "    if isinstance(value, type(tf.constant(0))):\n",
    "        value = value.numpy()\n",
    "    return tf.train.Feature(bytes_list=tf.train.BytesList(value=[value]))\n",
    "\n",
    "def _int64_feature(value):\n",
    "    \"\"\"Returns an int64_list from a bool / enum / int / uint.\"\"\"\n",
    "    return tf.train.Feature(int64_list=tf.train.Int64List(value=[value]))\n",
    "\n",
    "def create_tfrecord(images_path, labels, tfrecord_filename):\n",
    "    with tf.io.TFRecordWriter(tfrecord_filename) as writer:\n",
    "        for label in labels:\n",
    "            path = images_path.format(label)\n",
    "            folder_data = os.listdir(path)\n",
    "            for image_path in folder_data:\n",
    "                image = cv2.imread(path + image_path, cv2.IMREAD_COLOR)\n",
    "                image_resized = cv2.resize(image, (224, 224))\n",
    "                img_bytes = cv2.imencode('.jpg', image_resized)[1].tostring()\n",
    "                \n",
    "                label_encoded = labels.index(label)\n",
    "\n",
    "                feature = {\n",
    "                    'image': _bytes_feature(img_bytes),\n",
    "                    'label': _int64_feature(label_encoded)\n",
    "                }\n",
    "                \n",
    "                example_proto = tf.train.Example(features=tf.train.Features(feature=feature))\n",
    "                writer.write(example_proto.SerializeToString())\n",
    "\n",
    "# Define paths and labels\n",
    "labels = os.listdir('data/train')\n",
    "train_path = 'data/train/{0}/'\n",
    "test_path = 'data/valid/{0}/'\n",
    "test_label = os.listdir('data/valid')\n",
    "\n",
    "# Creating TFRecords for training and testing data\n",
    "create_tfrecord(train_path, labels, \"train.tfrecord\")\n",
    "create_tfrecord(test_path, test_label, \"test.tfrecord\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "34e6a804",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def decode_tfrecord(example_proto):\n",
    "    feature_description = {\n",
    "        'image': tf.io.FixedLenFeature([], tf.string),\n",
    "        'label': tf.io.FixedLenFeature([], tf.int64),\n",
    "    }\n",
    "    example = tf.io.parse_single_example(example_proto, feature_description)\n",
    "    image = tf.io.decode_jpeg(example['image'], channels=3)\n",
    "    image = tf.cast(image, tf.float32) / 255.0  # Normalize to [0,1]\n",
    "    label = example['label']\n",
    "    return image, label\n",
    "\n",
    "def load_dataset(tfrecord_name, batch_size):\n",
    "    raw_dataset = tf.data.TFRecordDataset(tfrecord_name)\n",
    "    dataset = raw_dataset.map(decode_tfrecord)\n",
    "    dataset = dataset.shuffle(1024).batch(batch_size).prefetch(tf.data.experimental.AUTOTUNE)\n",
    "    return dataset\n",
    "\n",
    "batch_size = 32\n",
    "train_dataset = load_dataset(\"train.tfrecord\", batch_size)\n",
    "test_dataset = load_dataset(\"test.tfrecord\", batch_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "772d79aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "num = []\n",
    "for label in labels:\n",
    "    k = 0\n",
    "    print('\\n', label.upper())\n",
    "    for image_path in x_data:\n",
    "        k = k+1\n",
    "    num.append(k)\n",
    "    print('there are ', k,' images in ', label, 'class')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "289dc5fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize = (8,8))\n",
    "plt.bar(labels, num)\n",
    "plt.title('NUMBER OF IMAGES CONTAINED IN EACH CLASS')\n",
    "plt.xlabel('classes')\n",
    "plt.xticks(rotation=90)\n",
    "plt.ylabel('count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eed8a6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(5, 2)\n",
    "fig.set_size_inches(15, 15)\n",
    "\n",
    "# Fetch a batch of data from the training dataset\n",
    "for images, labels in train_dataset.take(1):\n",
    "    images = images.numpy()\n",
    "    labels = labels.numpy()\n",
    "\n",
    "    for i in range(5):\n",
    "        for j in range(2):\n",
    "            l = rn.randint(0, batch_size - 1)\n",
    "            ax[i, j].imshow(images[l])\n",
    "            ax[i, j].set_title('Label: ' + str(labels[l]))\n",
    "\n",
    "plt.tight_layout()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb4b3051",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_data = np.array(x_data)\n",
    "\n",
    "y_data = np.array(y_data)\n",
    "\n",
    "print('the shape of X is: ', x_data.shape, 'and that of Y is: ', y_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86ee24",
   "metadata": {},
   "outputs": [],
   "source": [
    "le=LabelEncoder()\n",
    "Y=le.fit_transform(y_data)\n",
    "Y=to_categorical(Y,num_cls)\n",
    "x_data = x_data/255   #standarization \n",
    "Y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17c73dea",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications.inception_v3 import InceptionV3\n",
    "from tensorflow.keras.layers import Dense, GlobalAveragePooling2D\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.regularizers import l2\n",
    "\n",
    "def build_model(input_shape=(224, 224, 3)):\n",
    "    base_model = InceptionV3(weights='imagenet', include_top=False, input_shape=input_shape)\n",
    "    \n",
    "    for layer in base_model.layers[:]:\n",
    "        layer.trainable = False\n",
    "    \n",
    "    x = base_model.output\n",
    "    x = GlobalAveragePooling2D()(x)\n",
    "    x = Dense(1024, activation='relu', kernel_regularizer=l2())(x)\n",
    "    predictions = Dense(38, activation='softmax')(x)\n",
    "    \n",
    "    # Construct the final model\n",
    "    model = Model(inputs=base_model.input, outputs=predictions)\n",
    "    \n",
    "    # Compile the model with specified optimizer and loss\n",
    "    model.compile(optimizer=Adam(learning_rate=0.00001), loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    \n",
    "    return model\n",
    "\n",
    "# Build the model\n",
    "model = build_model()\n",
    "model.summary() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a439885b",
   "metadata": {},
   "outputs": [],
   "source": [
    "test_label = os.listdir('data/valid')\n",
    "print(test_label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc730adb",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test =[]\n",
    "y_test = []\n",
    "\n",
    "for label in test_label:\n",
    "    path = test_path.format(label)\n",
    "    folder_data = os.listdir(path)\n",
    "    for image_path in folder_data:\n",
    "        image = cv2.imread(path+image_path,cv2.IMREAD_COLOR)\n",
    "        image_resized = cv2.resize(image, (224,224))\n",
    "        x_test.append(np.array(image_resized))\n",
    "        y_test.append(label)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1817116",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = np.array(x_test)\n",
    "x_test = x_test/255\n",
    "y_test = np.array(y_test)\n",
    "le = LabelEncoder()\n",
    "y = le.fit_transform(y_test)\n",
    "y = to_categorical(y,num_cls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52e9f527",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test.shape,y.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d43d8bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.callbacks import EarlyStopping\n",
    "\n",
    "early_stop = EarlyStopping(monitor='val_loss', patience=7, verbose=1, mode='auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe5e9573",
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(x_data,Y,epochs = 50, validation_data = (x_test,y),\n",
    "                    verbose = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f7e75b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "    fig=plt.figure()\n",
    "    plt.plot(history.history['accuracy'])\n",
    "    plt.plot(history.history['val_accuracy'])    # plt.title('Model accuracy')\n",
    "    plt.ylabel('Accuracy')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    fig.savefig(\"accuracy.png\")\n",
    "    # # summarize history for loss\n",
    "    fig=plt.figure()\n",
    "    plt.plot(history.history['loss'])\n",
    "    plt.plot(history.history['val_loss'])\n",
    "    plt.title('Model loss')\n",
    "    plt.ylabel('Loss')\n",
    "    plt.xlabel('Epoch')\n",
    "    plt.legend(['train', 'test'], loc='upper left')\n",
    "    plt.show()\n",
    "    fig.savefig(\"loss.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e0d5844",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save('plantIncepV3.hdf5')\n",
    "# model.load_weights('plantIncepV3.hdf5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7601d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "from tensorflow.keras.preprocessing import image\n",
    "import numpy as np\n",
    "\n",
    "# # 1. Load the trained model\n",
    "model = load_model('plantIncepV3.hdf5')\n",
    "\n",
    "# 2. Preprocess the image\n",
    "def preprocess_image(img_path, target_size=(224, 224)):\n",
    "    img = image.load_img(img_path, target_size=target_size)\n",
    "    img_array = image.img_to_array(img)\n",
    "    img_array = np.expand_dims(img_array, axis=0)\n",
    "    img_array /= 255.  # Assuming your model uses the same normalization\n",
    "    return img_array\n",
    "\n",
    "img_path = 'bs123.png'\n",
    "img_array = preprocess_image(img_path)\n",
    "\n",
    "# 3. Predict\n",
    "predictions = model.predict(img_array)\n",
    "\n",
    "predicted_class = np.argmax(predictions[0])\n",
    "\n",
    "# 4. Postprocess (if needed)\n",
    "# If you have class names, you can map the predicted_class index to its name\n",
    "class_names = ['bs', 'ycv']  # Replace with your actual class names\n",
    "print(f\"Predicted class: {class_names[predicted_class]}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
